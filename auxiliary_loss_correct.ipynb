{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "import dlc_practical_prologue as prologue\n",
    "\n",
    "mini_batch_size = 100\n",
    "N = 1000\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(N)\n",
    "\n",
    "#normalize the input\n",
    "train_input/=255\n",
    "test_input/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_shapes_Net = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Siamese_net_auxiliary(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(Siamese_net_auxiliary, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(256, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 10)\n",
    "        self.fc3 = nn.Linear(20, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        if print_shapes_Net:\n",
    "            print(\"initial\", data.shape) #100 2 14 14\n",
    "            \n",
    "        class_layer = []\n",
    "        final_layer = []\n",
    "        for i in range(2):\n",
    "            x = data[:,i,:,:]\n",
    "            len0 = x.shape[0]\n",
    "            x = torch.reshape(x, (len0, 1, 14, 14))\n",
    "            \n",
    "            if print_shapes_Net:\n",
    "                print(\"X START\",x.shape) #[100, 1, 14, 14]\n",
    "            \n",
    "            x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2, stride=2))\n",
    "            if print_shapes_Net:\n",
    "                print(\"conv1\",x.shape) #[100, 32, 6, 6]\n",
    "                \n",
    "            x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "            if print_shapes_Net:\n",
    "                print(\"conv2\",x.shape) #[100, 64, 2, 2]\n",
    "            \n",
    "            x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "            if print_shapes_Net:\n",
    "                print(\"fc1\",x.shape) #[100, 64]\n",
    "            \n",
    "            x = F.relu(self.fc2(x))\n",
    "            if print_shapes_Net:\n",
    "                print(\"fc2\",x.shape) #[100 10]\n",
    "                \n",
    "            final_layer.append(x)\n",
    "            class_layer.append(x)\n",
    "            #class_layer.append(x.reshape(x.shape[0], 1, 10))\n",
    "            \n",
    "        final_layer = torch.cat((final_layer[1], final_layer[0]), 1)\n",
    "        class_layer = torch.cat((class_layer[0], class_layer[1]), 1)\n",
    "        class_layer = torch.reshape(class_layer, (len0, 2, 10))\n",
    "        \n",
    "        if print_shapes_Net:\n",
    "                print(\"class layer\",class_layer.shape) #[100, 2, 10]\n",
    "                \n",
    "        final_layer = self.fc3(final_layer)\n",
    "        if print_shapes_Net:\n",
    "            print(\"final\",final_layer.shape) #[100 2]\n",
    "            \n",
    "        return class_layer, final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Siamese_net_auxiliary_2(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(Siamese_net_auxiliary_2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(256, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 10)\n",
    "        self.fc3 = nn.Linear(20, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        if print_shapes_Net:\n",
    "            print(\"initial\", data.shape) #100 2 14 14\n",
    "            \n",
    "        class_layer = []\n",
    "        final_layer = []\n",
    "        for i in range(2):\n",
    "            x = data[:,i,:,:]\n",
    "            len0 = x.shape[0]\n",
    "            x = torch.reshape(x, (len0, 1, 14, 14))\n",
    "            \n",
    "            if print_shapes_Net:\n",
    "                print(\"X START\",x.shape) #[100, 1, 14, 14]\n",
    "            \n",
    "            x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2, stride=2))\n",
    "            if print_shapes_Net:\n",
    "                print(\"conv1\",x.shape) #[100, 32, 6, 6]\n",
    "                \n",
    "            x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "            if print_shapes_Net:\n",
    "                print(\"conv2\",x.shape) #[100, 64, 2, 2]\n",
    "            \n",
    "            x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "            if print_shapes_Net:\n",
    "                print(\"fc1\",x.shape) #[100, 64]\n",
    "            \n",
    "            x = F.relu(self.fc2(x))\n",
    "            if print_shapes_Net:\n",
    "                print(\"fc2\",x.shape) #[100 10]\n",
    "                \n",
    "            final_layer.append(x)\n",
    "            class_layer.append(x)\n",
    "            #class_layer.append(x.reshape(x.shape[0], 1, 10))\n",
    "            \n",
    "        final_layer = torch.cat((final_layer[0], final_layer[1]), 1)\n",
    "        class_layer = torch.cat((class_layer[0], class_layer[1]), 1)\n",
    "        class_layer = torch.reshape(class_layer, (len0, 2, 10))\n",
    "        \n",
    "        if print_shapes_Net:\n",
    "                print(\"class layer\",class_layer.shape) #[100, 2, 10]\n",
    "                \n",
    "        final_layer = self.fc3(final_layer)\n",
    "        if print_shapes_Net:\n",
    "            print(\"final\",final_layer.shape) #[100 2]\n",
    "            \n",
    "        return class_layer, final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_auxiliary_loss(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(Net_auxiliary_loss, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(256, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 20)\n",
    "        self.fc3 = nn.Linear(20, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if print_shapes_Net:\n",
    "            print(\"initial\", x.shape) #100 2 14 14\n",
    "        batchsize = x.shape[0]\n",
    "            \n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2, stride=2))\n",
    "        if print_shapes_Net:\n",
    "            print(\"conv1\",x.shape) #100 32 6 6\n",
    "            \n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        if print_shapes_Net:\n",
    "            print(\"conv2\",x.shape) #100 64 2 2\n",
    "            \n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        if print_shapes_Net:\n",
    "            print(\"fc1\",x.shape) #100 64        \n",
    "        \n",
    "        x_class = x\n",
    "            \n",
    "        x_class = self.fc2(x_class)\n",
    "        if print_shapes_Net:\n",
    "            print(\"final class\", x_class.shape) # 100 20 \n",
    "        x_try = x_class\n",
    "        \n",
    "        x_class = torch.reshape(x_class, (batchsize, 2, 10))\n",
    "        if print_shapes_Net:\n",
    "            print(\"x_class\",x_class.shape) # 100 2 10\n",
    "        \n",
    "            \n",
    "        x = self.fc3(x_try)\n",
    "        if print_shapes_Net:\n",
    "            print(\"fc1\",x.shape) #100 2 \n",
    "            \n",
    "        return x_class, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_auxiliary_loss_2(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(Net_auxiliary_loss_2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(128, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 10)\n",
    "        self.fc3 = nn.Linear(20, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if print_shapes_Net:\n",
    "            print(\"initial\", x.shape) #100 2 14 14\n",
    "        batchsize = x.shape[0]\n",
    "            \n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2, stride=2))\n",
    "        if print_shapes_Net:\n",
    "            print(\"conv1\",x.shape) #100 32 6 6\n",
    "            \n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        if print_shapes_Net:\n",
    "            print(\"conv2\",x.shape) #100 64 2 2\n",
    "            \n",
    "        x = F.relu(self.fc1(x.view(-1, 128)))\n",
    "        if print_shapes_Net:\n",
    "            print(\"fc1\",x.shape) #200 64        \n",
    "        \n",
    "        x_class = x\n",
    "            \n",
    "        x_class = self.fc2(x_class)\n",
    "        if print_shapes_Net:\n",
    "            print(\"final class\", x_class.shape) # 200 10 \n",
    "        x_try = torch.reshape(x_class, (batchsize, 20))\n",
    "        \n",
    "        x_class = torch.reshape(x_class, (batchsize, 2, 10))\n",
    "        if print_shapes_Net:\n",
    "            print(\"x_class\",x_class.shape) # 100 2 10\n",
    "        \n",
    "            \n",
    "        x = self.fc3(x_try)\n",
    "        if print_shapes_Net:\n",
    "            print(\"fc1\",x.shape) #100 2 \n",
    "            \n",
    "        return x_class, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch):\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    \n",
    "    for e in range(nb_epoch):\n",
    "        sum_loss = 0\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "          \n",
    "            output_class, output_target = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            #print(\"OUTPUT CLASS\", output_class[0])\n",
    "            #print(\"DESIRED CLASS\", train_classes.narrow(0, b, mini_batch_size)[0])\n",
    "            '''print(\"OUTPUT TARGET\", output_target.shape)\n",
    "            print(\"TARGET TARGET\", train_target.narrow(0, b, mini_batch_size).shape)\n",
    "            print(\"OUTPUT CLASS\", train_classes.narrow(0, b, mini_batch_size).shape)\n",
    "            print(\"TARGET CLASS\", train_classes_reshaped.shape)'''\n",
    "            \n",
    "            loss_class = criterion(output_class, train_classes.narrow(0, b, mini_batch_size))\n",
    "            loss_target = criterion(output_target, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad()\n",
    "            loss = loss_class + loss_target #*0.5\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            sum_loss = sum_loss + loss.item()\n",
    "        #print(e, sum_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor):\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    \n",
    "    for e in range(nb_epoch):\n",
    "        sum_loss = 0\n",
    "        sum_loss_target = 0\n",
    "        sum_loss_class = 0\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "          \n",
    "            output_class, output_target = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            output_class = torch.reshape(output_class, (-1, 10))\n",
    "            '''print(\"OUTPUT TARGET\", output_target.shape)\n",
    "            print(\"TARGET TARGET\", train_target.narrow(0, b, mini_batch_size).shape)\n",
    "            print(\"OUTPUT CLASS\", output_class.shape)\n",
    "            print(\"OUTPUT CLASS\", output_class[0])\n",
    "            print(\"TARGET CLASS\", train_classes.narrow(0, b, mini_batch_size)[0:1])'''\n",
    "            \n",
    "            \n",
    "            train_classes_reshaped = train_classes.narrow(0, b, mini_batch_size).view(-1) #with CrossEntropyLoss\n",
    "            '''print(\"TARGET CLASS RESHAPE\", train_classes_reshaped[0])\n",
    "            print(\"TARGET CLASS\", train_classes_reshaped.shape)\n",
    "            print(\"OUTPUT CLASS\", output_class[0])\n",
    "            print(\"TARGET CLASS\", train_classes_reshaped[0])'''\n",
    "            \n",
    "            loss_class = criterion(output_class, train_classes_reshaped)\n",
    "            loss_target = criterion(output_target, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad()\n",
    "            loss = loss_class + loss_target * loss_factor\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            sum_loss = sum_loss + loss.item()\n",
    "            sum_loss_target += loss_target\n",
    "            sum_loss_class += loss_class\n",
    "        '''print(e, sum_loss)\n",
    "        print(\"target\", sum_loss_target)\n",
    "        print(\"class\", sum_loss_class)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_BCE(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch):\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    \n",
    "    for e in range(nb_epoch):\n",
    "        sum_loss = 0\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "          \n",
    "            output_class, output_target = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            output_class = torch.reshape(output_class, (-1, 10))\n",
    "            '''print(\"OUTPUT TARGET\", output_target.shape)\n",
    "            print(\"TARGET TARGET\", train_target.narrow(0, b, mini_batch_size).shape)\n",
    "            print(\"OUTPUT CLASS\", output_class.shape)'''\n",
    "            \n",
    "            \n",
    "            train_classes_reshaped = torch.reshape(train_classes.narrow(0, b, mini_batch_size), (-1, 10)) #with BCELoss\n",
    "            #print(\"TARGET CLASS\", train_classes_reshaped.shape)\n",
    "            \n",
    "            loss_class = criterion(output_class, train_classes_reshaped)\n",
    "            loss_target = criterion(output_target, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad()\n",
    "            loss = loss_class + loss_target*0.5\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            sum_loss = sum_loss + loss.item()\n",
    "        #print(e, sum_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors_targets(model, input, target):\n",
    "    nb_errors = 0\n",
    "    _, output = model(input)\n",
    "    _, predicted_target = output.max(1) #max probabilities of target\n",
    "    \n",
    "    for b in range(1000):\n",
    "        if target[b,int(predicted_target[b])] <= 0:\n",
    "            nb_errors = nb_errors + 1\n",
    "            \n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors_classes(model, input, target):\n",
    "    nb_errors = 0\n",
    "\n",
    "    output,_ = model(input)\n",
    "    _, predicted_classes = output.max(2)\n",
    "\n",
    "    for b in range(input.shape[0]):\n",
    "        if target[b][0][predicted_classes[b][0]] <= 0:\n",
    "            nb_errors = nb_errors + 1\n",
    "        if target[b][1][predicted_classes[b][1]] <= 0:\n",
    "            nb_errors = nb_errors + 1\n",
    "\n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_target[1000,1]\n",
    "def reshape_target(train_target, test_target):\n",
    "    new_train_target = torch.empty(1000,2)\n",
    "    new_test_target = torch.empty(1000,2)\n",
    "    for i in range(1000):\n",
    "        if train_target[i] == 1 :\n",
    "            new_train_target[i,0] = 0\n",
    "            new_train_target[i,1] = 1\n",
    "\n",
    "        else:\n",
    "            new_train_target[i,0] = 1\n",
    "            new_train_target[i,1] = 0\n",
    "\n",
    "        if test_target[i] == 1:\n",
    "            new_test_target[i,0] = 0\n",
    "            new_test_target[i,1] = 1\n",
    "\n",
    "        else:\n",
    "            new_test_target[i,0] = 1\n",
    "            new_test_target[i,1] = 0\n",
    "            \n",
    "    return new_test_target, new_train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_classes[1000, 2]\n",
    "def reshape_classes(train_classes, test_classes):\n",
    "    new_train_classes = torch.zeros(1000, 2, 10)\n",
    "    new_test_classes = torch.zeros(1000, 2, 10)\n",
    "\n",
    "    for i in range(train_classes.shape[0]): #\n",
    "        new_train_classes[i][0][train_classes[i][0]] = 1\n",
    "        new_train_classes[i][1][train_classes[i][1]] = 1\n",
    "\n",
    "    for i in range(test_classes.shape[0]):\n",
    "        new_test_classes[i][0][test_classes[i][0]] = 1\n",
    "        new_test_classes[i][1][test_classes[i][1]] = 1\n",
    "\n",
    "    return new_train_classes, new_test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2])\n",
      "torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "print(train_classes.shape)\n",
    "print(train_classes.narrow(0, 0,100).view(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K 0\n",
      "TARGET train error Net_auxiliary_loss 20.60% 206/1000\n",
      "TARGET test error Net_auxiliary_loss 27.90% 279/1000\n",
      "CLASSES train error Net_auxiliary_loss 55.20% 1104/2000\n",
      "CLASSES test error Net_auxiliary_loss 54.45% 1089/2000\n",
      "K 1\n",
      "TARGET train error Net_auxiliary_loss 20.60% 206/1000\n",
      "TARGET test error Net_auxiliary_loss 24.80% 248/1000\n",
      "CLASSES train error Net_auxiliary_loss 49.45% 989/2000\n",
      "CLASSES test error Net_auxiliary_loss 51.30% 1026/2000\n",
      "K 2\n",
      "TARGET train error Net_auxiliary_loss 11.30% 113/1000\n",
      "TARGET test error Net_auxiliary_loss 19.20% 192/1000\n",
      "CLASSES train error Net_auxiliary_loss 50.05% 1001/2000\n",
      "CLASSES test error Net_auxiliary_loss 52.00% 1040/2000\n",
      "K 3\n",
      "TARGET train error Net_auxiliary_loss 4.40% 44/1000\n",
      "TARGET test error Net_auxiliary_loss 12.20% 122/1000\n",
      "CLASSES train error Net_auxiliary_loss 18.40% 368/2000\n",
      "CLASSES test error Net_auxiliary_loss 23.20% 464/2000\n",
      "K 4\n",
      "TARGET train error Net_auxiliary_loss 10.50% 105/1000\n",
      "TARGET test error Net_auxiliary_loss 12.60% 126/1000\n",
      "CLASSES train error Net_auxiliary_loss 39.65% 793/2000\n",
      "CLASSES test error Net_auxiliary_loss 41.45% 829/2000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-1f4ccc46b8b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mnb_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mloss_factor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mtrain_model_CEL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-97-d041ba052b66>\u001b[0m in \u001b[0;36mtrain_model_CEL\u001b[1;34m(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0moutput_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0moutput_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             '''print(\"OUTPUT TARGET\", output_target.shape)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-93-79e9dd877c85>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"conv1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#[100, 32, 6, 6]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mprint_shapes_Net\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"conv2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#[100, 64, 2, 2]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#WITH BCE\n",
    "####predict class of each digit\n",
    "for k in range(10):\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(N)\n",
    "    #normalize the input\n",
    "    train_input/=255\n",
    "    test_input/=255\n",
    "    new_train_classes, new_test_classes = reshape_classes(train_classes, test_classes)\n",
    "    new_test_target, new_train_target = reshape_target(train_target, test_target)\n",
    "    \n",
    "    model = Siamese_net_auxiliary(64)\n",
    "    lr = 0.005\n",
    "    nb_epoch = 25\n",
    "    loss_factor = 1\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    print(\"K\", k)\n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('TARGET train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('TARGET test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    \n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('CLASSES train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) /(2*train_input.size(0)),\n",
    "                                                      nb_train_errors_class, (2*train_input.size(0))))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('CLASSES test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / (2*test_input.size(0)),\n",
    "                                                    nb_test_errors_class, (2*test_input.size(0))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K 0\n",
      "TARGET train error Net_auxiliary_loss 6.60% 66/1000\n",
      "TARGET test error Net_auxiliary_loss 12.00% 120/1000\n",
      "CLASSES train error Net_auxiliary_loss 42.00% 840/2000\n",
      "CLASSES test error Net_auxiliary_loss 41.95% 839/2000\n",
      "K 1\n",
      "TARGET train error Net_auxiliary_loss 13.60% 136/1000\n",
      "TARGET test error Net_auxiliary_loss 20.50% 205/1000\n",
      "CLASSES train error Net_auxiliary_loss 38.80% 776/2000\n",
      "CLASSES test error Net_auxiliary_loss 42.00% 840/2000\n",
      "K 2\n",
      "TARGET train error Net_auxiliary_loss 5.60% 56/1000\n",
      "TARGET test error Net_auxiliary_loss 10.10% 101/1000\n",
      "CLASSES train error Net_auxiliary_loss 29.60% 592/2000\n",
      "CLASSES test error Net_auxiliary_loss 33.85% 677/2000\n",
      "K 3\n",
      "TARGET train error Net_auxiliary_loss 4.90% 49/1000\n",
      "TARGET test error Net_auxiliary_loss 14.50% 145/1000\n",
      "CLASSES train error Net_auxiliary_loss 21.50% 430/2000\n",
      "CLASSES test error Net_auxiliary_loss 25.20% 504/2000\n",
      "K 4\n",
      "TARGET train error Net_auxiliary_loss 11.50% 115/1000\n",
      "TARGET test error Net_auxiliary_loss 18.70% 187/1000\n",
      "CLASSES train error Net_auxiliary_loss 49.95% 999/2000\n",
      "CLASSES test error Net_auxiliary_loss 50.30% 1006/2000\n"
     ]
    }
   ],
   "source": [
    "#WITH BCE\n",
    "####BON SENS POUR LES CLASSES ET LES TARGETS\n",
    "for k in range(5):\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(N)\n",
    "    #normalize the input\n",
    "    train_input/=255\n",
    "    test_input/=255\n",
    "    new_train_classes, new_test_classes = reshape_classes(train_classes, test_classes)\n",
    "    new_test_target, new_train_target = reshape_target(train_target, test_target)\n",
    "    \n",
    "    model = Siamese_net_auxiliary_2(64)\n",
    "    lr = 0.005\n",
    "    nb_epoch = 25\n",
    "    loss_factor = 1\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    print(\"K\", k)\n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('TARGET train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('TARGET test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    \n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('CLASSES train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) /(2*train_input.size(0)),\n",
    "                                                      nb_train_errors_class, (2*train_input.size(0))))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('CLASSES test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / (2*test_input.size(0)),\n",
    "                                                    nb_test_errors_class, (2*test_input.size(0))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:  0.0005\n",
      "train error Net_auxiliary_loss 17.00% 170/1000\n",
      "test error Net_auxiliary_loss 19.20% 192/1000\n",
      "train error Net_auxiliary_loss 49.70% 497/1000\n",
      "test error Net_auxiliary_loss 49.20% 492/1000\n",
      "LR:  0.001\n",
      "train error Net_auxiliary_loss 17.90% 179/1000\n",
      "test error Net_auxiliary_loss 21.20% 212/1000\n",
      "train error Net_auxiliary_loss 52.60% 526/1000\n",
      "test error Net_auxiliary_loss 52.50% 525/1000\n",
      "LR:  0.005\n",
      "train error Net_auxiliary_loss 10.80% 108/1000\n",
      "test error Net_auxiliary_loss 15.70% 157/1000\n",
      "train error Net_auxiliary_loss 44.10% 441/1000\n",
      "test error Net_auxiliary_loss 47.20% 472/1000\n",
      "LR:  0.01\n",
      "train error Net_auxiliary_loss 19.30% 193/1000\n",
      "test error Net_auxiliary_loss 25.40% 254/1000\n",
      "train error Net_auxiliary_loss 99.30% 993/1000\n",
      "test error Net_auxiliary_loss 105.30% 1053/1000\n",
      "LR:  0.05\n",
      "train error Net_auxiliary_loss 15.30% 153/1000\n",
      "test error Net_auxiliary_loss 20.90% 209/1000\n",
      "train error Net_auxiliary_loss 164.90% 1649/1000\n",
      "test error Net_auxiliary_loss 165.80% 1658/1000\n",
      "LR:  0.1\n",
      "train error Net_auxiliary_loss 47.20% 472/1000\n",
      "test error Net_auxiliary_loss 46.50% 465/1000\n",
      "train error Net_auxiliary_loss 180.20% 1802/1000\n",
      "test error Net_auxiliary_loss 180.60% 1806/1000\n",
      "LR:  0.5\n",
      "train error Net_auxiliary_loss 55.40% 554/1000\n",
      "test error Net_auxiliary_loss 56.00% 560/1000\n",
      "train error Net_auxiliary_loss 182.30% 1823/1000\n",
      "test error Net_auxiliary_loss 179.60% 1796/1000\n"
     ]
    }
   ],
   "source": [
    "#WITH BCE\n",
    "####LR\n",
    "for lr in [0.0005, 0.001,0.005, 0.01, 0.05, 0.1, 0.5]:\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(N)\n",
    "    #normalize the input\n",
    "    train_input/=255\n",
    "    test_input/=255\n",
    "    new_train_classes, new_test_classes = reshape_classes(train_classes, test_classes)\n",
    "    new_test_target, new_train_target = reshape_target(train_target, test_target)\n",
    "    \n",
    "    model = Siamese_net_auxiliary(64)\n",
    "    #lr = 0.005\n",
    "    nb_epoch = 25\n",
    "    loss_factor = 1\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    print(\"LR: \", lr)\n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    \n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                      nb_train_errors_class, train_input.size(0)))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                    nb_test_errors_class, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NET AUXILIARY LOSS 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss_2 0.20% 2/1000\n",
      "test error Net_auxiliary_loss_2 15.90% 159/1000\n",
      "train error Net_auxiliary_loss 3.80% 38/1000\n",
      "test error Net_auxiliary_loss 23.10% 231/1000\n"
     ]
    }
   ],
   "source": [
    "#WITH CROSS ENTROPY\n",
    "####predict class of each digit\n",
    "for k in range(1):\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(N)\n",
    "    #normalize the input\n",
    "    train_input/=255\n",
    "    test_input/=255\n",
    "    \n",
    "    new_train_classes, new_test_classes = reshape_classes(train_classes, test_classes)\n",
    "    new_test_target, new_train_target = reshape_target(train_target, test_target)\n",
    "    \n",
    "\n",
    "    model = Net_auxiliary_loss_2(64)\n",
    "    lr = 0.005\n",
    "    nb_epoch = 25\n",
    "    loss_factor = 1\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss_2 {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss_2 {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                      nb_train_errors_class, train_input.size(0)))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                    nb_test_errors_class, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.0005\n",
      "train error Net_auxiliary_loss 8.70% 87/1000\n",
      "test error Net_auxiliary_loss 23.50% 235/1000\n",
      "train error Net_auxiliary_loss 10.40% 104/1000\n",
      "test error Net_auxiliary_loss 179.30% 1793/1000\n",
      "LR: 0.001\n",
      "train error Net_auxiliary_loss 7.90% 79/1000\n",
      "test error Net_auxiliary_loss 23.20% 232/1000\n",
      "train error Net_auxiliary_loss 11.20% 112/1000\n",
      "test error Net_auxiliary_loss 180.10% 1801/1000\n",
      "LR: 0.005\n",
      "train error Net_auxiliary_loss 2.20% 22/1000\n",
      "test error Net_auxiliary_loss 19.10% 191/1000\n",
      "train error Net_auxiliary_loss 18.90% 189/1000\n",
      "test error Net_auxiliary_loss 178.00% 1780/1000\n",
      "LR: 0.01\n",
      "train error Net_auxiliary_loss 4.70% 47/1000\n",
      "test error Net_auxiliary_loss 26.70% 267/1000\n",
      "train error Net_auxiliary_loss 26.20% 262/1000\n",
      "test error Net_auxiliary_loss 178.60% 1786/1000\n",
      "LR: 0.05\n",
      "train error Net_auxiliary_loss 44.20% 442/1000\n",
      "test error Net_auxiliary_loss 43.90% 439/1000\n",
      "train error Net_auxiliary_loss 177.30% 1773/1000\n",
      "test error Net_auxiliary_loss 178.40% 1784/1000\n",
      "LR: 0.1\n",
      "train error Net_auxiliary_loss 46.30% 463/1000\n",
      "test error Net_auxiliary_loss 45.90% 459/1000\n",
      "train error Net_auxiliary_loss 177.20% 1772/1000\n",
      "test error Net_auxiliary_loss 180.50% 1805/1000\n",
      "LR: 0.5\n",
      "train error Net_auxiliary_loss 45.00% 450/1000\n",
      "test error Net_auxiliary_loss 44.50% 445/1000\n",
      "train error Net_auxiliary_loss 177.70% 1777/1000\n",
      "test error Net_auxiliary_loss 178.40% 1784/1000\n"
     ]
    }
   ],
   "source": [
    "#LR CHOICE: 0.005\n",
    "\n",
    "for lr in [0.0005, 0.001,0.005, 0.01, 0.05, 0.1, 0.5]:\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(N)\n",
    "    new_train_classes, new_test_target = reshape_classes(train_classes, test_classes)\n",
    "    new_test_target, new_train_target = reshape_target(train_target, test_target)\n",
    "    \n",
    "    model = Net_auxiliary_loss_2(64)\n",
    "    nb_epoch = 25\n",
    "    loss_factor = 1\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    print(\"LR:\", lr)\n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                      nb_train_errors_class, train_input.size(0)))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                    nb_test_errors_class, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB HIDDEN: 64\n",
      "train error Net_auxiliary_loss 7.30% 73/1000\n",
      "test error Net_auxiliary_loss 23.90% 239/1000\n",
      "train error Net_auxiliary_loss 101.10% 1011/1000\n",
      "test error Net_auxiliary_loss 181.90% 1819/1000\n",
      "NB HIDDEN: 128\n",
      "train error Net_auxiliary_loss 9.80% 98/1000\n",
      "test error Net_auxiliary_loss 27.00% 270/1000\n",
      "train error Net_auxiliary_loss 44.00% 440/1000\n",
      "test error Net_auxiliary_loss 179.60% 1796/1000\n",
      "NB HIDDEN: 256\n",
      "train error Net_auxiliary_loss 17.70% 177/1000\n",
      "test error Net_auxiliary_loss 28.40% 284/1000\n",
      "train error Net_auxiliary_loss 88.20% 882/1000\n",
      "test error Net_auxiliary_loss 179.50% 1795/1000\n"
     ]
    }
   ],
   "source": [
    "#NB HIDDEN CHOICE: 64\n",
    "\n",
    "for nb_hidden in [64, 128, 256]:\n",
    "    model = Net_auxiliary_loss(nb_hidden)\n",
    "    nb_epoch = 25\n",
    "    lr = 0.005\n",
    "    loss_factor = 1\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    print(\"NB HIDDEN:\", nb_hidden)\n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                      nb_train_errors_class, train_input.size(0)))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                    nb_test_errors_class, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS FACTOR: 0\n",
      "train error Net_auxiliary_loss 43.60% 436/1000\n",
      "test error Net_auxiliary_loss 44.30% 443/1000\n",
      "train error Net_auxiliary_loss 8.10% 81/1000\n",
      "test error Net_auxiliary_loss 33.40% 334/1000\n",
      "LOSS FACTOR: 0.2\n",
      "train error Net_auxiliary_loss 7.60% 76/1000\n",
      "test error Net_auxiliary_loss 18.10% 181/1000\n",
      "train error Net_auxiliary_loss 3.70% 37/1000\n",
      "test error Net_auxiliary_loss 30.80% 308/1000\n",
      "LOSS FACTOR: 0.4\n",
      "train error Net_auxiliary_loss 3.40% 34/1000\n",
      "test error Net_auxiliary_loss 17.90% 179/1000\n",
      "train error Net_auxiliary_loss 4.90% 49/1000\n",
      "test error Net_auxiliary_loss 29.80% 298/1000\n",
      "LOSS FACTOR: 0.5\n",
      "train error Net_auxiliary_loss 9.80% 98/1000\n",
      "test error Net_auxiliary_loss 19.60% 196/1000\n",
      "train error Net_auxiliary_loss 9.30% 93/1000\n",
      "test error Net_auxiliary_loss 35.10% 351/1000\n",
      "LOSS FACTOR: 0.6\n",
      "train error Net_auxiliary_loss 7.60% 76/1000\n",
      "test error Net_auxiliary_loss 20.10% 201/1000\n",
      "train error Net_auxiliary_loss 3.60% 36/1000\n",
      "test error Net_auxiliary_loss 29.20% 292/1000\n",
      "LOSS FACTOR: 1\n",
      "train error Net_auxiliary_loss 0.90% 9/1000\n",
      "test error Net_auxiliary_loss 17.80% 178/1000\n",
      "train error Net_auxiliary_loss 8.20% 82/1000\n",
      "test error Net_auxiliary_loss 29.10% 291/1000\n"
     ]
    }
   ],
   "source": [
    "#LOSS FACTOR CHOICE: 1\n",
    "\n",
    "for loss_factor in [0, 0.2, 0.4, 0.5, 0.6, 1]:\n",
    "    model = Net_auxiliary_loss(64)\n",
    "    nb_epoch = 25\n",
    "    lr = 0.005\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    print(\"LOSS FACTOR:\", loss_factor)\n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                      nb_train_errors_class, train_input.size(0)))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                    nb_test_errors_class, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss_2 2.60% 26/1000\n",
      "test error Net_auxiliary_loss_2 16.70% 167/1000\n",
      "train error Net_auxiliary_loss 7.90% 79/1000\n",
      "test error Net_auxiliary_loss 21.40% 214/1000\n",
      "train error Net_auxiliary_loss_2 0.10% 1/1000\n",
      "test error Net_auxiliary_loss_2 16.80% 168/1000\n",
      "train error Net_auxiliary_loss 1.00% 10/1000\n",
      "test error Net_auxiliary_loss 22.00% 220/1000\n",
      "train error Net_auxiliary_loss_2 1.80% 18/1000\n",
      "test error Net_auxiliary_loss_2 17.50% 175/1000\n",
      "train error Net_auxiliary_loss 4.90% 49/1000\n",
      "test error Net_auxiliary_loss 27.20% 272/1000\n",
      "train error Net_auxiliary_loss_2 0.80% 8/1000\n",
      "test error Net_auxiliary_loss_2 15.80% 158/1000\n",
      "train error Net_auxiliary_loss 2.90% 29/1000\n",
      "test error Net_auxiliary_loss 19.50% 195/1000\n",
      "train error Net_auxiliary_loss_2 0.00% 0/1000\n",
      "test error Net_auxiliary_loss_2 14.40% 144/1000\n",
      "train error Net_auxiliary_loss 1.80% 18/1000\n",
      "test error Net_auxiliary_loss 19.70% 197/1000\n"
     ]
    }
   ],
   "source": [
    "#FINAL TEST\n",
    "\n",
    "for k in range(5):\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(N)\n",
    "    #normalize the input\n",
    "    train_input/=255\n",
    "    test_input/=255\n",
    "    \n",
    "    new_train_classes, new_test_classes = reshape_classes(train_classes, test_classes)\n",
    "    new_test_target, new_train_target = reshape_target(train_target, test_target)\n",
    "    \n",
    "\n",
    "    model = Net_auxiliary_loss_2(64)\n",
    "    lr = 0.005\n",
    "    nb_epoch = 25\n",
    "    loss_factor = 1\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss_2 {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss_2 {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                      nb_train_errors_class, train_input.size(0)))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                    nb_test_errors_class, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NET AUXILIARY LOSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOSS NORMALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.5065331757068634\n",
      "1 2.2292163521051407\n",
      "2 2.0670663565397263\n",
      "3 1.8218588531017303\n",
      "4 1.5977305173873901\n",
      "5 1.428273156285286\n",
      "6 1.253657266497612\n",
      "7 1.1575968489050865\n",
      "8 1.0382725298404694\n",
      "9 0.9629436209797859\n",
      "10 0.8976012691855431\n",
      "11 0.967954084277153\n",
      "12 1.0874886959791183\n",
      "13 0.8518436625599861\n",
      "14 0.8097478002309799\n",
      "15 0.7159438878297806\n",
      "16 0.677453063428402\n",
      "17 0.646220538765192\n",
      "18 0.6273945681750774\n",
      "19 0.6054331138730049\n",
      "20 0.5870510935783386\n",
      "21 0.5822736211121082\n",
      "22 0.6565598733723164\n",
      "23 0.8934471942484379\n",
      "24 0.8616812080144882\n",
      "train error Net_auxiliary_loss 0.90% 9/1000\n",
      "test error Net_auxiliary_loss 16.40% 164/1000\n"
     ]
    }
   ],
   "source": [
    "####predict class of each digit\n",
    "for k in range(1):\n",
    "    model = Net_auxiliary_loss(64)\n",
    "    lr = 0.005\n",
    "    nb_epoch = 25\n",
    "    train_model(model, train_input, new_train_classes, new_train_target, mini_batch_size, lr, nb_epoch)\n",
    "    \n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss 71.70% 717/1000\n",
      "test error Net_auxiliary_loss 81.60% 816/1000\n"
     ]
    }
   ],
   "source": [
    "nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                  nb_train_errors_class, train_input.size(0)))\n",
    "nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                nb_test_errors_class, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CROSS ENTROPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss 6.60% 66/1000\n",
      "test error Net_auxiliary_loss 17.30% 173/1000\n"
     ]
    }
   ],
   "source": [
    "#WITH CROSS ENTROPY\n",
    "####predict class of each digit\n",
    "for k in range(1):\n",
    "    model = Net_auxiliary_loss(256)\n",
    "    lr = 0.001\n",
    "    nb_epoch = 25\n",
    "    loss_factor = 1\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss 13.30% 133/1000\n",
      "test error Net_auxiliary_loss 37.60% 376/1000\n"
     ]
    }
   ],
   "source": [
    "nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                  nb_train_errors_class, train_input.size(0)))\n",
    "nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                nb_test_errors_class, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.0005\n",
      "train error Net_auxiliary_loss 21.40% 214/1000\n",
      "test error Net_auxiliary_loss 23.30% 233/1000\n",
      "train error Net_auxiliary_loss 52.90% 529/1000\n",
      "test error Net_auxiliary_loss 60.60% 606/1000\n",
      "LR: 0.001\n",
      "train error Net_auxiliary_loss 13.30% 133/1000\n",
      "test error Net_auxiliary_loss 19.60% 196/1000\n",
      "train error Net_auxiliary_loss 26.50% 265/1000\n",
      "test error Net_auxiliary_loss 41.00% 410/1000\n",
      "LR: 0.005\n",
      "train error Net_auxiliary_loss 6.20% 62/1000\n",
      "test error Net_auxiliary_loss 21.70% 217/1000\n",
      "train error Net_auxiliary_loss 13.70% 137/1000\n",
      "test error Net_auxiliary_loss 36.40% 364/1000\n",
      "LR: 0.01\n",
      "train error Net_auxiliary_loss 3.90% 39/1000\n",
      "test error Net_auxiliary_loss 20.80% 208/1000\n",
      "train error Net_auxiliary_loss 28.70% 287/1000\n",
      "test error Net_auxiliary_loss 60.60% 606/1000\n",
      "LR: 0.05\n",
      "train error Net_auxiliary_loss 44.90% 449/1000\n",
      "test error Net_auxiliary_loss 47.40% 474/1000\n",
      "train error Net_auxiliary_loss 174.80% 1748/1000\n",
      "test error Net_auxiliary_loss 176.80% 1768/1000\n",
      "LR: 0.1\n",
      "train error Net_auxiliary_loss 44.90% 449/1000\n",
      "test error Net_auxiliary_loss 47.40% 474/1000\n",
      "train error Net_auxiliary_loss 174.80% 1748/1000\n",
      "test error Net_auxiliary_loss 176.80% 1768/1000\n",
      "LR: 0.5\n",
      "train error Net_auxiliary_loss 55.10% 551/1000\n",
      "test error Net_auxiliary_loss 52.60% 526/1000\n",
      "train error Net_auxiliary_loss 176.10% 1761/1000\n",
      "test error Net_auxiliary_loss 178.60% 1786/1000\n"
     ]
    }
   ],
   "source": [
    "#LR CHOICE: 0.001\n",
    "\n",
    "for lr in [0.0005, 0.001,0.005, 0.01, 0.05, 0.1, 0.5]:\n",
    "    model = Net_auxiliary_loss(64)\n",
    "    nb_epoch = 25\n",
    "    loss_factor = 1\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    print(\"LR:\", lr)\n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                      nb_train_errors_class, train_input.size(0)))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                    nb_test_errors_class, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB HIDDEN: 64\n",
      "train error Net_auxiliary_loss 7.30% 73/1000\n",
      "test error Net_auxiliary_loss 18.60% 186/1000\n",
      "train error Net_auxiliary_loss 34.40% 344/1000\n",
      "test error Net_auxiliary_loss 46.30% 463/1000\n",
      "NB HIDDEN: 128\n",
      "train error Net_auxiliary_loss 7.40% 74/1000\n",
      "test error Net_auxiliary_loss 19.00% 190/1000\n",
      "train error Net_auxiliary_loss 28.50% 285/1000\n",
      "test error Net_auxiliary_loss 41.60% 416/1000\n",
      "NB HIDDEN: 256\n",
      "train error Net_auxiliary_loss 6.10% 61/1000\n",
      "test error Net_auxiliary_loss 17.10% 171/1000\n",
      "train error Net_auxiliary_loss 19.60% 196/1000\n",
      "test error Net_auxiliary_loss 34.70% 347/1000\n"
     ]
    }
   ],
   "source": [
    "#NB HIDDEN CHOICE: 256\n",
    "\n",
    "for nb_hidden in [64, 128, 256]:\n",
    "    model = Net_auxiliary_loss(nb_hidden)\n",
    "    nb_epoch = 25\n",
    "    lr = 0.001\n",
    "    loss_factor = 1\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    print(\"NB HIDDEN:\", nb_hidden)\n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                      nb_train_errors_class, train_input.size(0)))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                    nb_test_errors_class, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB HIDDEN: 256\n",
      "train error Net_auxiliary_loss 54.30% 543/1000\n",
      "test error Net_auxiliary_loss 55.80% 558/1000\n",
      "train error Net_auxiliary_loss 20.50% 205/1000\n",
      "test error Net_auxiliary_loss 32.50% 325/1000\n",
      "NB HIDDEN: 256\n",
      "train error Net_auxiliary_loss 24.90% 249/1000\n",
      "test error Net_auxiliary_loss 27.40% 274/1000\n",
      "train error Net_auxiliary_loss 30.20% 302/1000\n",
      "test error Net_auxiliary_loss 42.60% 426/1000\n",
      "NB HIDDEN: 256\n",
      "train error Net_auxiliary_loss 17.50% 175/1000\n",
      "test error Net_auxiliary_loss 22.20% 222/1000\n",
      "train error Net_auxiliary_loss 24.30% 243/1000\n",
      "test error Net_auxiliary_loss 39.20% 392/1000\n",
      "NB HIDDEN: 256\n",
      "train error Net_auxiliary_loss 21.60% 216/1000\n",
      "test error Net_auxiliary_loss 23.90% 239/1000\n",
      "train error Net_auxiliary_loss 30.30% 303/1000\n",
      "test error Net_auxiliary_loss 43.30% 433/1000\n",
      "NB HIDDEN: 256\n",
      "train error Net_auxiliary_loss 10.70% 107/1000\n",
      "test error Net_auxiliary_loss 18.50% 185/1000\n",
      "train error Net_auxiliary_loss 27.10% 271/1000\n",
      "test error Net_auxiliary_loss 41.80% 418/1000\n",
      "NB HIDDEN: 256\n",
      "train error Net_auxiliary_loss 10.10% 101/1000\n",
      "test error Net_auxiliary_loss 18.60% 186/1000\n",
      "train error Net_auxiliary_loss 40.40% 404/1000\n",
      "test error Net_auxiliary_loss 52.00% 520/1000\n"
     ]
    }
   ],
   "source": [
    "#LOSS FACTOR CHOICE\n",
    "\n",
    "for loss_factor in [0, 0.2, 0.4, 0.5, 0.6, 1]:\n",
    "    model = Net_auxiliary_loss(64)\n",
    "    nb_epoch = 25\n",
    "    lr = 0.001\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    print(\"NB HIDDEN:\", nb_hidden)\n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                      nb_train_errors_class, train_input.size(0)))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                    nb_test_errors_class, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BCE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss 5.20% 52/1000\n",
      "test error Net_auxiliary_loss 19.90% 199/1000\n"
     ]
    }
   ],
   "source": [
    "#WITH BCE\n",
    "####predict class of each digit\n",
    "for k in range(1):\n",
    "    model = Net_auxiliary_loss(64)\n",
    "    lr = 0.005\n",
    "    nb_epoch = 25\n",
    "    train_model_BCE(model, train_input, new_train_classes, new_train_target, mini_batch_size, lr, nb_epoch)\n",
    "    \n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss 58.30% 583/1000\n",
      "test error Net_auxiliary_loss 74.20% 742/1000\n"
     ]
    }
   ],
   "source": [
    "nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                  nb_train_errors_class, train_input.size(0)))\n",
    "nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                nb_test_errors_class, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIAMESE NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss 0.00% 0/1000\n",
      "test error Net_auxiliary_loss 21.70% 217/1000\n"
     ]
    }
   ],
   "source": [
    "####MSE Loss\n",
    "for k in range(1):\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(N)\n",
    "    #normalize the input\n",
    "    train_input/=255\n",
    "    test_input/=255\n",
    "    new_train_classes, new_test_classes = reshape_classes(train_classes, test_classes)\n",
    "    new_test_target, new_train_target = reshape_target(train_target, test_target)\n",
    "    \n",
    "    model = Siamese_net_auxiliary()\n",
    "    lr = 0.005\n",
    "    nb_epoch = 25\n",
    "    train_model(model, train_input, new_train_classes, new_train_target, mini_batch_size, lr, nb_epoch)\n",
    "    \n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss 182.30% 1823/1000\n",
      "test error Net_auxiliary_loss 182.70% 1827/1000\n"
     ]
    }
   ],
   "source": [
    "nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                  nb_train_errors_class, train_input.size(0)))\n",
    "nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                nb_test_errors_class, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WITH CROSS ENTROPY LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss 171.20% 1712/1000\n",
      "test error Net_auxiliary_loss 182.10% 1821/1000\n"
     ]
    }
   ],
   "source": [
    "nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                  nb_train_errors_class, train_input.size(0)))\n",
    "nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                nb_test_errors_class, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WITH BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13.854893326759338\n",
      "1 13.82936429977417\n",
      "2 13.821517586708069\n",
      "3 13.816715240478516\n",
      "4 13.813976883888245\n",
      "5 13.812509298324585\n",
      "6 13.811757564544678\n",
      "7 13.811380863189697\n",
      "8 13.811193943023682\n",
      "9 13.811100363731384\n",
      "10 13.811052918434143\n",
      "11 13.811028361320496\n",
      "12 13.811017036437988\n",
      "13 13.811012268066406\n",
      "14 13.811010479927063\n",
      "15 13.811010003089905\n",
      "16 13.81101131439209\n",
      "17 13.811011910438538\n",
      "18 13.811012983322144\n",
      "19 13.81101369857788\n",
      "20 13.811014533042908\n",
      "21 13.811015725135803\n",
      "22 13.811015963554382\n",
      "23 13.81101667881012\n",
      "24 13.811017036437988\n",
      "train error Net_auxiliary_loss 44.90% 449/1000\n",
      "test error Net_auxiliary_loss 47.40% 474/1000\n"
     ]
    }
   ],
   "source": [
    "#WITH BCE\n",
    "####predict class of each digit\n",
    "for k in range(1):\n",
    "    model = Siamese_net_auxiliary()\n",
    "    lr = 0.005\n",
    "    nb_epoch = 25\n",
    "    train_model_BCE(model, train_input, new_train_classes, new_train_target, mini_batch_size, lr, nb_epoch)\n",
    "    \n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR 0.0005\n",
      "train error Net_auxiliary_loss 9.20% 92/1000\n",
      "test error Net_auxiliary_loss 16.90% 169/1000\n",
      "train error Net_auxiliary_loss 171.80% 1718/1000\n",
      "test error Net_auxiliary_loss 178.70% 1787/1000\n",
      "LR 0.001\n",
      "train error Net_auxiliary_loss 7.00% 70/1000\n",
      "test error Net_auxiliary_loss 19.10% 191/1000\n",
      "train error Net_auxiliary_loss 175.70% 1757/1000\n",
      "test error Net_auxiliary_loss 179.10% 1791/1000\n",
      "LR 0.005\n",
      "train error Net_auxiliary_loss 0.90% 9/1000\n",
      "test error Net_auxiliary_loss 18.70% 187/1000\n",
      "train error Net_auxiliary_loss 180.50% 1805/1000\n",
      "test error Net_auxiliary_loss 181.40% 1814/1000\n",
      "LR 0.01\n",
      "train error Net_auxiliary_loss 0.40% 4/1000\n",
      "test error Net_auxiliary_loss 20.10% 201/1000\n",
      "train error Net_auxiliary_loss 180.00% 1800/1000\n",
      "test error Net_auxiliary_loss 182.30% 1823/1000\n",
      "LR 0.05\n",
      "train error Net_auxiliary_loss 44.90% 449/1000\n",
      "test error Net_auxiliary_loss 47.40% 474/1000\n",
      "train error Net_auxiliary_loss 181.80% 1818/1000\n",
      "test error Net_auxiliary_loss 179.00% 1790/1000\n",
      "LR 0.1\n",
      "train error Net_auxiliary_loss 44.90% 449/1000\n",
      "test error Net_auxiliary_loss 47.40% 474/1000\n",
      "train error Net_auxiliary_loss 180.10% 1801/1000\n",
      "test error Net_auxiliary_loss 178.30% 1783/1000\n",
      "LR 0.5\n",
      "train error Net_auxiliary_loss 55.10% 551/1000\n",
      "test error Net_auxiliary_loss 52.60% 526/1000\n",
      "train error Net_auxiliary_loss 180.40% 1804/1000\n",
      "test error Net_auxiliary_loss 180.70% 1807/1000\n"
     ]
    }
   ],
   "source": [
    "#### lr = 0.0005 seems to not overfit\n",
    "for lr in [0.0005, 0.001,0.005, 0.01, 0.05, 0.1, 0.5]:\n",
    "    model = Siamese_net_auxiliary()\n",
    "    nb_epoch = 25\n",
    "    train_model(model, train_input, new_train_classes, new_train_target, mini_batch_size, lr, nb_epoch)\n",
    "    \n",
    "    print(\"LR\", lr)\n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    \n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                      nb_train_errors_class, train_input.size(0)))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                    nb_test_errors_class, test_input.size(0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss 16.80% 168/1000\n",
      "test error Net_auxiliary_loss 22.00% 220/1000\n",
      "train error Net_auxiliary_loss 176.80% 1768/1000\n",
      "test error Net_auxiliary_loss 180.00% 1800/1000\n",
      "train error Net_auxiliary_loss 11.70% 117/1000\n",
      "test error Net_auxiliary_loss 19.70% 197/1000\n",
      "train error Net_auxiliary_loss 176.70% 1767/1000\n",
      "test error Net_auxiliary_loss 179.40% 1794/1000\n",
      "train error Net_auxiliary_loss 11.20% 112/1000\n",
      "test error Net_auxiliary_loss 16.40% 164/1000\n",
      "train error Net_auxiliary_loss 177.10% 1771/1000\n",
      "test error Net_auxiliary_loss 180.00% 1800/1000\n",
      "train error Net_auxiliary_loss 14.60% 146/1000\n",
      "test error Net_auxiliary_loss 20.40% 204/1000\n",
      "train error Net_auxiliary_loss 176.50% 1765/1000\n",
      "test error Net_auxiliary_loss 180.50% 1805/1000\n",
      "train error Net_auxiliary_loss 44.90% 449/1000\n",
      "test error Net_auxiliary_loss 47.40% 474/1000\n",
      "train error Net_auxiliary_loss 180.90% 1809/1000\n",
      "test error Net_auxiliary_loss 181.10% 1811/1000\n",
      "train error Net_auxiliary_loss 14.30% 143/1000\n",
      "test error Net_auxiliary_loss 18.40% 184/1000\n",
      "train error Net_auxiliary_loss 179.10% 1791/1000\n",
      "test error Net_auxiliary_loss 180.50% 1805/1000\n",
      "train error Net_auxiliary_loss 20.50% 205/1000\n",
      "test error Net_auxiliary_loss 25.80% 258/1000\n",
      "train error Net_auxiliary_loss 176.00% 1760/1000\n",
      "test error Net_auxiliary_loss 179.20% 1792/1000\n",
      "train error Net_auxiliary_loss 10.00% 100/1000\n",
      "test error Net_auxiliary_loss 17.00% 170/1000\n",
      "train error Net_auxiliary_loss 177.80% 1778/1000\n",
      "test error Net_auxiliary_loss 179.80% 1798/1000\n",
      "train error Net_auxiliary_loss 11.40% 114/1000\n",
      "test error Net_auxiliary_loss 16.90% 169/1000\n",
      "train error Net_auxiliary_loss 175.50% 1755/1000\n",
      "test error Net_auxiliary_loss 181.40% 1814/1000\n",
      "train error Net_auxiliary_loss 14.80% 148/1000\n",
      "test error Net_auxiliary_loss 22.20% 222/1000\n",
      "train error Net_auxiliary_loss 178.80% 1788/1000\n",
      "test error Net_auxiliary_loss 180.00% 1800/1000\n"
     ]
    }
   ],
   "source": [
    "####predict class of each digit\n",
    "for k in range(10):\n",
    "    model = Siamese_net_auxiliary()\n",
    "    lr = 0.0005\n",
    "    nb_epoch = 25\n",
    "    train_model(model, train_input, new_train_classes, new_train_target, mini_batch_size, lr, nb_epoch)\n",
    "    \n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    \n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                      nb_train_errors_class, train_input.size(0)))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                    nb_test_errors_class, test_input.size(0)))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
