{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "import dlc_practical_prologue as prologue\n",
    "\n",
    "mini_batch_size = 100\n",
    "N = 1000\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(N)\n",
    "\n",
    "#normalize the input\n",
    "train_input/=255\n",
    "test_input/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_shapes_Net = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Siamese_net_auxiliary(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Siamese_net_auxiliary, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(256, 10)\n",
    "        self.fc2 = nn.Linear(20, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        if print_shapes_Net:\n",
    "            print(\"initial\", data.shape) #100 2 14 14\n",
    "            \n",
    "        class_layer = []\n",
    "        final_layer = []\n",
    "        for i in range(2):\n",
    "            x = data[:,i,:,:]\n",
    "            len0 = x.shape[0]\n",
    "            x = torch.reshape(x, (len0, 1, 14, 14))\n",
    "            \n",
    "            if print_shapes_Net:\n",
    "                print(\"X START\",x.shape) \n",
    "            \n",
    "            x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2, stride=2))\n",
    "            if print_shapes_Net:\n",
    "                print(\"conv1\",x.shape) \n",
    "                \n",
    "            x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "            if print_shapes_Net:\n",
    "                print(\"conv2\",x.shape)\n",
    "            \n",
    "            x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "            if print_shapes_Net:\n",
    "                print(\"fc1\",x.shape) \n",
    "                \n",
    "            final_layer.append(x)\n",
    "            class_layer.append(x.reshape(x.shape[0], 1, 10))\n",
    "            \n",
    "        final_layer = torch.cat((final_layer[1], final_layer[0]), 1)\n",
    "        class_layer = torch.cat((class_layer[1], class_layer[0]), 1)\n",
    "        \n",
    "        if print_shapes_Net:\n",
    "                print(\"class layer\",class_layer.shape) #[100, 2, 10]\n",
    "                \n",
    "        final_layer = self.fc2(final_layer)\n",
    "        if print_shapes_Net:\n",
    "            print(\"final\",final_layer.shape) \n",
    "            \n",
    "        return class_layer, final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_auxiliary_loss(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(Net_auxiliary_loss, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(256, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 20)\n",
    "        self.fc3 = nn.Linear(20, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if print_shapes_Net:\n",
    "            print(\"initial\", x.shape) #100 2 14 14\n",
    "        batchsize = x.shape[0]\n",
    "            \n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2, stride=2))\n",
    "        if print_shapes_Net:\n",
    "            print(\"conv1\",x.shape) #100 32 6 6\n",
    "            \n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        if print_shapes_Net:\n",
    "            print(\"conv2\",x.shape) #100 64 2 2\n",
    "            \n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        if print_shapes_Net:\n",
    "            print(\"fc1\",x.shape) #100 64        \n",
    "        \n",
    "        x_class = x\n",
    "            \n",
    "        x_class = self.fc2(x_class)\n",
    "        if print_shapes_Net:\n",
    "            print(\"final class\", x_class.shape) # 100 20 \n",
    "        x_try = x_class\n",
    "        \n",
    "        x_class = torch.reshape(x_class, (batchsize, 2, 10))\n",
    "        if print_shapes_Net:\n",
    "            print(\"x_class\",x_class.shape) # 100 2 10\n",
    "        \n",
    "            \n",
    "        x = self.fc3(x_try)\n",
    "        if print_shapes_Net:\n",
    "            print(\"fc1\",x.shape) #100 2 \n",
    "            \n",
    "        return x_class, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_auxiliary_loss_2(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(Net_auxiliary_loss_2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(128, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 10)\n",
    "        self.fc3 = nn.Linear(20, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if print_shapes_Net:\n",
    "            print(\"initial\", x.shape) #100 2 14 14\n",
    "        batchsize = x.shape[0]\n",
    "            \n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2, stride=2))\n",
    "        if print_shapes_Net:\n",
    "            print(\"conv1\",x.shape) #100 32 6 6\n",
    "            \n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        if print_shapes_Net:\n",
    "            print(\"conv2\",x.shape) #100 64 2 2\n",
    "            \n",
    "        x = F.relu(self.fc1(x.view(-1, 128)))\n",
    "        if print_shapes_Net:\n",
    "            print(\"fc1\",x.shape) #200 64        \n",
    "        \n",
    "        x_class = x\n",
    "            \n",
    "        x_class = self.fc2(x_class)\n",
    "        if print_shapes_Net:\n",
    "            print(\"final class\", x_class.shape) # 200 10 \n",
    "        x_try = torch.reshape(x_class, (batchsize, 20))\n",
    "        \n",
    "        x_class = torch.reshape(x_class, (batchsize, 2, 10))\n",
    "        if print_shapes_Net:\n",
    "            print(\"x_class\",x_class.shape) # 100 2 10\n",
    "        \n",
    "            \n",
    "        x = self.fc3(x_try)\n",
    "        if print_shapes_Net:\n",
    "            print(\"fc1\",x.shape) #100 2 \n",
    "            \n",
    "        return x_class, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch):\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    \n",
    "    for e in range(nb_epoch):\n",
    "        sum_loss = 0\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "          \n",
    "            output_class, output_target = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            #print(\"OUTPUT CLASS\", output_class[0])\n",
    "            #print(\"DESIRED CLASS\", train_classes.narrow(0, b, mini_batch_size)[0])\n",
    "            '''print(\"OUTPUT TARGET\", output_target.shape)\n",
    "            print(\"TARGET TARGET\", train_target.narrow(0, b, mini_batch_size).shape)\n",
    "            print(\"OUTPUT CLASS\", train_classes.narrow(0, b, mini_batch_size).shape)\n",
    "            print(\"TARGET CLASS\", train_classes_reshaped.shape)'''\n",
    "            \n",
    "            loss_class = criterion(output_class, train_classes.narrow(0, b, mini_batch_size))\n",
    "            loss_target = criterion(output_target, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad()\n",
    "            loss = loss_class + loss_target #*0.5\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            sum_loss = sum_loss + loss.item()\n",
    "        #print(e, sum_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor):\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    \n",
    "    for e in range(nb_epoch):\n",
    "        sum_loss = 0\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "          \n",
    "            output_class, output_target = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            output_class = torch.reshape(output_class, (-1, 10))\n",
    "            '''print(\"OUTPUT TARGET\", output_target.shape)\n",
    "            print(\"TARGET TARGET\", train_target.narrow(0, b, mini_batch_size).shape)\n",
    "            print(\"OUTPUT CLASS\", output_class.shape)'''\n",
    "            \n",
    "            train_classes_reshaped = train_classes.narrow(0, b, mini_batch_size).view(-1) #with CrossEntropyLoss\n",
    "            #print(\"TARGET CLASS\", train_classes_reshaped.shape)\n",
    "            \n",
    "            loss_class = criterion(output_class, train_classes_reshaped)\n",
    "            loss_target = criterion(output_target, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad()\n",
    "            loss = loss_class + loss_target * loss_factor\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            sum_loss = sum_loss + loss.item()\n",
    "        #print(e, sum_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_BCE(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch):\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    \n",
    "    for e in range(nb_epoch):\n",
    "        sum_loss = 0\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "          \n",
    "            output_class, output_target = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            output_class = torch.reshape(output_class, (-1, 10))\n",
    "            '''print(\"OUTPUT TARGET\", output_target.shape)\n",
    "            print(\"TARGET TARGET\", train_target.narrow(0, b, mini_batch_size).shape)\n",
    "            print(\"OUTPUT CLASS\", output_class.shape)'''\n",
    "            \n",
    "            \n",
    "            train_classes_reshaped = torch.reshape(train_classes.narrow(0, b, mini_batch_size), (-1, 10)) #with BCELoss\n",
    "            #print(\"TARGET CLASS\", train_classes_reshaped.shape)\n",
    "            \n",
    "            loss_class = criterion(output_class, train_classes_reshaped)\n",
    "            loss_target = criterion(output_target, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad()\n",
    "            loss = loss_class + loss_target*0.5\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            sum_loss = sum_loss + loss.item()\n",
    "        #print(e, sum_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors_targets(model, input, target):\n",
    "    nb_errors = 0\n",
    "    _, output = model(input)\n",
    "    _, predicted_target = output.max(1) #max probabilities of target\n",
    "    \n",
    "    for b in range(1000):\n",
    "        if target[b,int(predicted_target[b])] <= 0:\n",
    "            nb_errors = nb_errors + 1\n",
    "            \n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors_classes(model, input, target):\n",
    "    nb_errors = 0\n",
    "\n",
    "    output,_ = model(input)\n",
    "    _, predicted_classes = output.max(2)\n",
    "\n",
    "    for b in range(input.shape[0]):\n",
    "        if target[b][0][predicted_classes[b][0]] <= 0:\n",
    "            nb_errors = nb_errors + 1\n",
    "        if target[b][1][predicted_classes[b][1]] <= 0:\n",
    "            nb_errors = nb_errors + 1\n",
    "\n",
    "    return nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_target[1000,1]\n",
    "new_train_target = torch.empty(1000,2)\n",
    "new_test_target = torch.empty(1000,2)\n",
    "for i in range(1000):\n",
    "    if train_target[i] == 1 :\n",
    "        new_train_target[i,0] = 0\n",
    "        new_train_target[i,1] = 1\n",
    "        \n",
    "    else:\n",
    "        new_train_target[i,0] = 1\n",
    "        new_train_target[i,1] = 0\n",
    "        \n",
    "    if test_target[i] == 1:\n",
    "        new_test_target[i,0] = 0\n",
    "        new_test_target[i,1] = 1\n",
    "        \n",
    "    else:\n",
    "        new_test_target[i,0] = 1\n",
    "        new_test_target[i,1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_classes[1000, 2]\n",
    "new_train_classes = torch.zeros(1000, 2, 10)\n",
    "new_test_classes = torch.zeros(1000, 2, 10)\n",
    "\n",
    "for i in range(train_classes.shape[0]): #\n",
    "    new_train_classes[i][0][train_classes[i][0]] = 1\n",
    "    new_train_classes[i][1][train_classes[i][1]] = 1\n",
    "\n",
    "for i in range(test_classes.shape[0]):\n",
    "    new_test_classes[i][0][test_classes[i][0]] = 1\n",
    "    new_test_classes[i][1][test_classes[i][1]] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NET AUXILIARY LOSS 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss 7.00% 70/1000\n",
      "test error Net_auxiliary_loss 18.90% 189/1000\n"
     ]
    }
   ],
   "source": [
    "#WITH CROSS ENTROPY\n",
    "####predict class of each digit\n",
    "for k in range(1):\n",
    "    model = Net_auxiliary_loss_2(64)\n",
    "    lr = 0.005\n",
    "    nb_epoch = 25\n",
    "    loss_factor = 1\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss 7.30% 73/1000\n",
      "test error Net_auxiliary_loss 26.00% 260/1000\n"
     ]
    }
   ],
   "source": [
    "nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                  nb_train_errors_class, train_input.size(0)))\n",
    "nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                nb_test_errors_class, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.0005\n",
      "train error Net_auxiliary_loss 17.00% 170/1000\n",
      "test error Net_auxiliary_loss 18.70% 187/1000\n",
      "train error Net_auxiliary_loss 33.80% 338/1000\n",
      "test error Net_auxiliary_loss 39.30% 393/1000\n",
      "LR: 0.001\n",
      "train error Net_auxiliary_loss 12.70% 127/1000\n",
      "test error Net_auxiliary_loss 19.50% 195/1000\n",
      "train error Net_auxiliary_loss 21.50% 215/1000\n",
      "test error Net_auxiliary_loss 31.90% 319/1000\n",
      "LR: 0.005\n",
      "train error Net_auxiliary_loss 0.60% 6/1000\n",
      "test error Net_auxiliary_loss 15.50% 155/1000\n",
      "train error Net_auxiliary_loss 5.20% 52/1000\n",
      "test error Net_auxiliary_loss 24.20% 242/1000\n",
      "LR: 0.01\n",
      "train error Net_auxiliary_loss 1.40% 14/1000\n",
      "test error Net_auxiliary_loss 15.80% 158/1000\n",
      "train error Net_auxiliary_loss 15.00% 150/1000\n",
      "test error Net_auxiliary_loss 33.80% 338/1000\n",
      "LR: 0.05\n",
      "train error Net_auxiliary_loss 44.90% 449/1000\n",
      "test error Net_auxiliary_loss 47.40% 474/1000\n",
      "train error Net_auxiliary_loss 174.80% 1748/1000\n",
      "test error Net_auxiliary_loss 176.80% 1768/1000\n",
      "LR: 0.1\n",
      "train error Net_auxiliary_loss 44.90% 449/1000\n",
      "test error Net_auxiliary_loss 47.40% 474/1000\n",
      "train error Net_auxiliary_loss 174.80% 1748/1000\n",
      "test error Net_auxiliary_loss 176.80% 1768/1000\n",
      "LR: 0.5\n",
      "train error Net_auxiliary_loss 55.10% 551/1000\n",
      "test error Net_auxiliary_loss 52.60% 526/1000\n",
      "train error Net_auxiliary_loss 174.80% 1748/1000\n",
      "test error Net_auxiliary_loss 176.80% 1768/1000\n"
     ]
    }
   ],
   "source": [
    "#LR CHOICE: 0.005\n",
    "\n",
    "for lr in [0.0005, 0.001,0.005, 0.01, 0.05, 0.1, 0.5]:\n",
    "    model = Net_auxiliary_loss_2(64)\n",
    "    nb_epoch = 25\n",
    "    loss_factor = 1\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    print(\"LR:\", lr)\n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                      nb_train_errors_class, train_input.size(0)))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                    nb_test_errors_class, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB HIDDEN: 64\n",
      "train error Net_auxiliary_loss 0.20% 2/1000\n",
      "test error Net_auxiliary_loss 16.70% 167/1000\n",
      "train error Net_auxiliary_loss 7.10% 71/1000\n",
      "test error Net_auxiliary_loss 33.60% 336/1000\n",
      "NB HIDDEN: 128\n",
      "train error Net_auxiliary_loss 2.70% 27/1000\n",
      "test error Net_auxiliary_loss 17.40% 174/1000\n",
      "train error Net_auxiliary_loss 5.90% 59/1000\n",
      "test error Net_auxiliary_loss 34.20% 342/1000\n",
      "NB HIDDEN: 256\n",
      "train error Net_auxiliary_loss 8.60% 86/1000\n",
      "test error Net_auxiliary_loss 22.60% 226/1000\n",
      "train error Net_auxiliary_loss 6.20% 62/1000\n",
      "test error Net_auxiliary_loss 33.50% 335/1000\n"
     ]
    }
   ],
   "source": [
    "#NB HIDDEN CHOICE: 64\n",
    "\n",
    "for nb_hidden in [64, 128, 256]:\n",
    "    model = Net_auxiliary_loss(nb_hidden)\n",
    "    nb_epoch = 25\n",
    "    lr = 0.005\n",
    "    loss_factor = 1\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    print(\"NB HIDDEN:\", nb_hidden)\n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                      nb_train_errors_class, train_input.size(0)))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                    nb_test_errors_class, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS FACTOR: 0\n",
      "train error Net_auxiliary_loss 43.60% 436/1000\n",
      "test error Net_auxiliary_loss 44.30% 443/1000\n",
      "train error Net_auxiliary_loss 8.10% 81/1000\n",
      "test error Net_auxiliary_loss 33.40% 334/1000\n",
      "LOSS FACTOR: 0.2\n",
      "train error Net_auxiliary_loss 7.60% 76/1000\n",
      "test error Net_auxiliary_loss 18.10% 181/1000\n",
      "train error Net_auxiliary_loss 3.70% 37/1000\n",
      "test error Net_auxiliary_loss 30.80% 308/1000\n",
      "LOSS FACTOR: 0.4\n",
      "train error Net_auxiliary_loss 3.40% 34/1000\n",
      "test error Net_auxiliary_loss 17.90% 179/1000\n",
      "train error Net_auxiliary_loss 4.90% 49/1000\n",
      "test error Net_auxiliary_loss 29.80% 298/1000\n",
      "LOSS FACTOR: 0.5\n",
      "train error Net_auxiliary_loss 9.80% 98/1000\n",
      "test error Net_auxiliary_loss 19.60% 196/1000\n",
      "train error Net_auxiliary_loss 9.30% 93/1000\n",
      "test error Net_auxiliary_loss 35.10% 351/1000\n",
      "LOSS FACTOR: 0.6\n",
      "train error Net_auxiliary_loss 7.60% 76/1000\n",
      "test error Net_auxiliary_loss 20.10% 201/1000\n",
      "train error Net_auxiliary_loss 3.60% 36/1000\n",
      "test error Net_auxiliary_loss 29.20% 292/1000\n",
      "LOSS FACTOR: 1\n",
      "train error Net_auxiliary_loss 0.90% 9/1000\n",
      "test error Net_auxiliary_loss 17.80% 178/1000\n",
      "train error Net_auxiliary_loss 8.20% 82/1000\n",
      "test error Net_auxiliary_loss 29.10% 291/1000\n"
     ]
    }
   ],
   "source": [
    "#LOSS FACTOR CHOICE: 1\n",
    "\n",
    "for loss_factor in [0, 0.2, 0.4, 0.5, 0.6, 1]:\n",
    "    model = Net_auxiliary_loss(64)\n",
    "    nb_epoch = 25\n",
    "    lr = 0.005\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    print(\"LOSS FACTOR:\", loss_factor)\n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                      nb_train_errors_class, train_input.size(0)))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                    nb_test_errors_class, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 1\n",
      "train error Net_auxiliary_loss 0.60% 6/1000\n",
      "test error Net_auxiliary_loss 16.20% 162/1000\n",
      "train error Net_auxiliary_loss 7.00% 70/1000\n",
      "test error Net_auxiliary_loss 33.10% 331/1000\n",
      "I: 2\n",
      "train error Net_auxiliary_loss 1.40% 14/1000\n",
      "test error Net_auxiliary_loss 18.00% 180/1000\n",
      "train error Net_auxiliary_loss 14.00% 140/1000\n",
      "test error Net_auxiliary_loss 35.80% 358/1000\n",
      "I: 3\n",
      "train error Net_auxiliary_loss 0.60% 6/1000\n",
      "test error Net_auxiliary_loss 17.30% 173/1000\n",
      "train error Net_auxiliary_loss 11.10% 111/1000\n",
      "test error Net_auxiliary_loss 35.00% 350/1000\n",
      "I: 4\n",
      "train error Net_auxiliary_loss 1.40% 14/1000\n",
      "test error Net_auxiliary_loss 16.50% 165/1000\n",
      "train error Net_auxiliary_loss 8.40% 84/1000\n",
      "test error Net_auxiliary_loss 35.20% 352/1000\n",
      "I: 5\n",
      "train error Net_auxiliary_loss 0.70% 7/1000\n",
      "test error Net_auxiliary_loss 16.30% 163/1000\n",
      "train error Net_auxiliary_loss 9.30% 93/1000\n",
      "test error Net_auxiliary_loss 32.00% 320/1000\n"
     ]
    }
   ],
   "source": [
    "#FINAL TEST\n",
    "\n",
    "for i in range(5):\n",
    "    model = Net_auxiliary_loss(64)\n",
    "    nb_epoch = 25\n",
    "    lr = 0.005\n",
    "    loss_factor = 1\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    print(\"I:\", i + 1)\n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                      nb_train_errors_class, train_input.size(0)))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                    nb_test_errors_class, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NET AUXILIARY LOSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOSS NORMALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.5065331757068634\n",
      "1 2.2292163521051407\n",
      "2 2.0670663565397263\n",
      "3 1.8218588531017303\n",
      "4 1.5977305173873901\n",
      "5 1.428273156285286\n",
      "6 1.253657266497612\n",
      "7 1.1575968489050865\n",
      "8 1.0382725298404694\n",
      "9 0.9629436209797859\n",
      "10 0.8976012691855431\n",
      "11 0.967954084277153\n",
      "12 1.0874886959791183\n",
      "13 0.8518436625599861\n",
      "14 0.8097478002309799\n",
      "15 0.7159438878297806\n",
      "16 0.677453063428402\n",
      "17 0.646220538765192\n",
      "18 0.6273945681750774\n",
      "19 0.6054331138730049\n",
      "20 0.5870510935783386\n",
      "21 0.5822736211121082\n",
      "22 0.6565598733723164\n",
      "23 0.8934471942484379\n",
      "24 0.8616812080144882\n",
      "train error Net_auxiliary_loss 0.90% 9/1000\n",
      "test error Net_auxiliary_loss 16.40% 164/1000\n"
     ]
    }
   ],
   "source": [
    "####predict class of each digit\n",
    "for k in range(1):\n",
    "    model = Net_auxiliary_loss(64)\n",
    "    lr = 0.005\n",
    "    nb_epoch = 25\n",
    "    train_model(model, train_input, new_train_classes, new_train_target, mini_batch_size, lr, nb_epoch)\n",
    "    \n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss 71.70% 717/1000\n",
      "test error Net_auxiliary_loss 81.60% 816/1000\n"
     ]
    }
   ],
   "source": [
    "nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                  nb_train_errors_class, train_input.size(0)))\n",
    "nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                nb_test_errors_class, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CROSS ENTROPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss 6.60% 66/1000\n",
      "test error Net_auxiliary_loss 17.30% 173/1000\n"
     ]
    }
   ],
   "source": [
    "#WITH CROSS ENTROPY\n",
    "####predict class of each digit\n",
    "for k in range(1):\n",
    "    model = Net_auxiliary_loss(256)\n",
    "    lr = 0.001\n",
    "    nb_epoch = 25\n",
    "    loss_factor = 1\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss 13.30% 133/1000\n",
      "test error Net_auxiliary_loss 37.60% 376/1000\n"
     ]
    }
   ],
   "source": [
    "nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                  nb_train_errors_class, train_input.size(0)))\n",
    "nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                nb_test_errors_class, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.0005\n",
      "train error Net_auxiliary_loss 21.40% 214/1000\n",
      "test error Net_auxiliary_loss 23.30% 233/1000\n",
      "train error Net_auxiliary_loss 52.90% 529/1000\n",
      "test error Net_auxiliary_loss 60.60% 606/1000\n",
      "LR: 0.001\n",
      "train error Net_auxiliary_loss 13.30% 133/1000\n",
      "test error Net_auxiliary_loss 19.60% 196/1000\n",
      "train error Net_auxiliary_loss 26.50% 265/1000\n",
      "test error Net_auxiliary_loss 41.00% 410/1000\n",
      "LR: 0.005\n",
      "train error Net_auxiliary_loss 6.20% 62/1000\n",
      "test error Net_auxiliary_loss 21.70% 217/1000\n",
      "train error Net_auxiliary_loss 13.70% 137/1000\n",
      "test error Net_auxiliary_loss 36.40% 364/1000\n",
      "LR: 0.01\n",
      "train error Net_auxiliary_loss 3.90% 39/1000\n",
      "test error Net_auxiliary_loss 20.80% 208/1000\n",
      "train error Net_auxiliary_loss 28.70% 287/1000\n",
      "test error Net_auxiliary_loss 60.60% 606/1000\n",
      "LR: 0.05\n",
      "train error Net_auxiliary_loss 44.90% 449/1000\n",
      "test error Net_auxiliary_loss 47.40% 474/1000\n",
      "train error Net_auxiliary_loss 174.80% 1748/1000\n",
      "test error Net_auxiliary_loss 176.80% 1768/1000\n",
      "LR: 0.1\n",
      "train error Net_auxiliary_loss 44.90% 449/1000\n",
      "test error Net_auxiliary_loss 47.40% 474/1000\n",
      "train error Net_auxiliary_loss 174.80% 1748/1000\n",
      "test error Net_auxiliary_loss 176.80% 1768/1000\n",
      "LR: 0.5\n",
      "train error Net_auxiliary_loss 55.10% 551/1000\n",
      "test error Net_auxiliary_loss 52.60% 526/1000\n",
      "train error Net_auxiliary_loss 176.10% 1761/1000\n",
      "test error Net_auxiliary_loss 178.60% 1786/1000\n"
     ]
    }
   ],
   "source": [
    "#LR CHOICE: 0.001\n",
    "\n",
    "for lr in [0.0005, 0.001,0.005, 0.01, 0.05, 0.1, 0.5]:\n",
    "    model = Net_auxiliary_loss(64)\n",
    "    nb_epoch = 25\n",
    "    loss_factor = 1\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    print(\"LR:\", lr)\n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                      nb_train_errors_class, train_input.size(0)))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                    nb_test_errors_class, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB HIDDEN: 64\n",
      "train error Net_auxiliary_loss 7.30% 73/1000\n",
      "test error Net_auxiliary_loss 18.60% 186/1000\n",
      "train error Net_auxiliary_loss 34.40% 344/1000\n",
      "test error Net_auxiliary_loss 46.30% 463/1000\n",
      "NB HIDDEN: 128\n",
      "train error Net_auxiliary_loss 7.40% 74/1000\n",
      "test error Net_auxiliary_loss 19.00% 190/1000\n",
      "train error Net_auxiliary_loss 28.50% 285/1000\n",
      "test error Net_auxiliary_loss 41.60% 416/1000\n",
      "NB HIDDEN: 256\n",
      "train error Net_auxiliary_loss 6.10% 61/1000\n",
      "test error Net_auxiliary_loss 17.10% 171/1000\n",
      "train error Net_auxiliary_loss 19.60% 196/1000\n",
      "test error Net_auxiliary_loss 34.70% 347/1000\n"
     ]
    }
   ],
   "source": [
    "#NB HIDDEN CHOICE: 256\n",
    "\n",
    "for nb_hidden in [64, 128, 256]:\n",
    "    model = Net_auxiliary_loss(nb_hidden)\n",
    "    nb_epoch = 25\n",
    "    lr = 0.001\n",
    "    loss_factor = 1\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    print(\"NB HIDDEN:\", nb_hidden)\n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                      nb_train_errors_class, train_input.size(0)))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                    nb_test_errors_class, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB HIDDEN: 256\n",
      "train error Net_auxiliary_loss 54.30% 543/1000\n",
      "test error Net_auxiliary_loss 55.80% 558/1000\n",
      "train error Net_auxiliary_loss 20.50% 205/1000\n",
      "test error Net_auxiliary_loss 32.50% 325/1000\n",
      "NB HIDDEN: 256\n",
      "train error Net_auxiliary_loss 24.90% 249/1000\n",
      "test error Net_auxiliary_loss 27.40% 274/1000\n",
      "train error Net_auxiliary_loss 30.20% 302/1000\n",
      "test error Net_auxiliary_loss 42.60% 426/1000\n",
      "NB HIDDEN: 256\n",
      "train error Net_auxiliary_loss 17.50% 175/1000\n",
      "test error Net_auxiliary_loss 22.20% 222/1000\n",
      "train error Net_auxiliary_loss 24.30% 243/1000\n",
      "test error Net_auxiliary_loss 39.20% 392/1000\n",
      "NB HIDDEN: 256\n",
      "train error Net_auxiliary_loss 21.60% 216/1000\n",
      "test error Net_auxiliary_loss 23.90% 239/1000\n",
      "train error Net_auxiliary_loss 30.30% 303/1000\n",
      "test error Net_auxiliary_loss 43.30% 433/1000\n",
      "NB HIDDEN: 256\n",
      "train error Net_auxiliary_loss 10.70% 107/1000\n",
      "test error Net_auxiliary_loss 18.50% 185/1000\n",
      "train error Net_auxiliary_loss 27.10% 271/1000\n",
      "test error Net_auxiliary_loss 41.80% 418/1000\n",
      "NB HIDDEN: 256\n",
      "train error Net_auxiliary_loss 10.10% 101/1000\n",
      "test error Net_auxiliary_loss 18.60% 186/1000\n",
      "train error Net_auxiliary_loss 40.40% 404/1000\n",
      "test error Net_auxiliary_loss 52.00% 520/1000\n"
     ]
    }
   ],
   "source": [
    "#LOSS FACTOR CHOICE\n",
    "\n",
    "for loss_factor in [0, 0.2, 0.4, 0.5, 0.6, 1]:\n",
    "    model = Net_auxiliary_loss(64)\n",
    "    nb_epoch = 25\n",
    "    lr = 0.001\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch, loss_factor)\n",
    "    \n",
    "    print(\"NB HIDDEN:\", nb_hidden)\n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                      nb_train_errors_class, train_input.size(0)))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                    nb_test_errors_class, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BCE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss 5.20% 52/1000\n",
      "test error Net_auxiliary_loss 19.90% 199/1000\n"
     ]
    }
   ],
   "source": [
    "#WITH BCE\n",
    "####predict class of each digit\n",
    "for k in range(1):\n",
    "    model = Net_auxiliary_loss(64)\n",
    "    lr = 0.005\n",
    "    nb_epoch = 25\n",
    "    train_model_BCE(model, train_input, new_train_classes, new_train_target, mini_batch_size, lr, nb_epoch)\n",
    "    \n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss 58.30% 583/1000\n",
      "test error Net_auxiliary_loss 74.20% 742/1000\n"
     ]
    }
   ],
   "source": [
    "nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                  nb_train_errors_class, train_input.size(0)))\n",
    "nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                nb_test_errors_class, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIAMESE NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial torch.Size([100, 2, 14, 14])\n",
      "X START torch.Size([100, 1, 14, 14])\n",
      "conv1 torch.Size([100, 32, 6, 6])\n",
      "conv2 torch.Size([100, 64, 2, 2])\n",
      "fc1 torch.Size([100, 10])\n",
      "X START torch.Size([100, 1, 14, 14])\n",
      "conv1 torch.Size([100, 32, 6, 6])\n",
      "conv2 torch.Size([100, 64, 2, 2])\n",
      "fc1 torch.Size([100, 10])\n",
      "class layer torch.Size([100, 2, 10])\n",
      "final torch.Size([100, 2])\n",
      "initial torch.Size([100, 2, 14, 14])\n",
      "X START torch.Size([100, 1, 14, 14])\n",
      "conv1 torch.Size([100, 32, 6, 6])\n",
      "conv2 torch.Size([100, 64, 2, 2])\n",
      "fc1 torch.Size([100, 10])\n",
      "X START torch.Size([100, 1, 14, 14])\n",
      "conv1 torch.Size([100, 32, 6, 6])\n",
      "conv2 torch.Size([100, 64, 2, 2])\n",
      "fc1 torch.Size([100, 10])\n",
      "class layer torch.Size([100, 2, 10])\n",
      "final torch.Size([100, 2])\n",
      "initial torch.Size([100, 2, 14, 14])\n",
      "X START torch.Size([100, 1, 14, 14])\n",
      "conv1 torch.Size([100, 32, 6, 6])\n",
      "conv2 torch.Size([100, 64, 2, 2])\n",
      "fc1 torch.Size([100, 10])\n",
      "X START torch.Size([100, 1, 14, 14])\n",
      "conv1 torch.Size([100, 32, 6, 6])\n",
      "conv2 torch.Size([100, 64, 2, 2])\n",
      "fc1 torch.Size([100, 10])\n",
      "class layer torch.Size([100, 2, 10])\n",
      "final torch.Size([100, 2])\n",
      "initial torch.Size([100, 2, 14, 14])\n",
      "X START torch.Size([100, 1, 14, 14])\n",
      "conv1 torch.Size([100, 32, 6, 6])\n",
      "conv2 torch.Size([100, 64, 2, 2])\n",
      "fc1 torch.Size([100, 10])\n",
      "X START torch.Size([100, 1, 14, 14])\n",
      "conv1 torch.Size([100, 32, 6, 6])\n",
      "conv2 torch.Size([100, 64, 2, 2])\n",
      "fc1 torch.Size([100, 10])\n",
      "class layer torch.Size([100, 2, 10])\n",
      "final torch.Size([100, 2])\n",
      "initial torch.Size([100, 2, 14, 14])\n",
      "X START torch.Size([100, 1, 14, 14])\n",
      "conv1 torch.Size([100, 32, 6, 6])\n",
      "conv2 torch.Size([100, 64, 2, 2])\n",
      "fc1 torch.Size([100, 10])\n",
      "X START torch.Size([100, 1, 14, 14])\n",
      "conv1 torch.Size([100, 32, 6, 6])\n",
      "conv2 torch.Size([100, 64, 2, 2])\n",
      "fc1 torch.Size([100, 10])\n",
      "class layer torch.Size([100, 2, 10])\n",
      "final torch.Size([100, 2])\n",
      "initial torch.Size([100, 2, 14, 14])\n",
      "X START torch.Size([100, 1, 14, 14])\n",
      "conv1 torch.Size([100, 32, 6, 6])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-37eb398321bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.005\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mnb_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_train_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_train_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mnb_train_errors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_nb_errors_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_train_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-98-6b0906fde29c>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0moutput_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[1;31m#print(\"OUTPUT CLASS\", output_class[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;31m#print(\"DESIRED CLASS\", train_classes.narrow(0, b, mini_batch_size)[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-dfb6398e7e9e>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"conv1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mprint_shapes_Net\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"conv2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####predict class of each digit\n",
    "for k in range(1):\n",
    "    model = Siamese_net_auxiliary()\n",
    "    lr = 0.005\n",
    "    nb_epoch = 25\n",
    "    train_model(model, train_input, new_train_classes, new_train_target, mini_batch_size, lr, nb_epoch)\n",
    "    \n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss 155.50% 1555/1000\n",
      "test error Net_auxiliary_loss 179.20% 1792/1000\n"
     ]
    }
   ],
   "source": [
    "nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                  nb_train_errors_class, train_input.size(0)))\n",
    "nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                nb_test_errors_class, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WITH CROSS ENTROPY LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 29.857958555221558\n",
      "1 29.60709547996521\n",
      "2 29.162097215652466\n",
      "3 28.624603271484375\n",
      "4 28.073718309402466\n",
      "5 27.53482723236084\n",
      "6 27.035579204559326\n",
      "7 26.584228038787842\n",
      "8 26.154109001159668\n",
      "9 25.831193447113037\n",
      "10 25.491074323654175\n",
      "11 25.116344928741455\n",
      "12 24.854015350341797\n",
      "13 24.579912424087524\n",
      "14 24.3172447681427\n",
      "15 24.091768980026245\n",
      "16 23.86699342727661\n",
      "17 23.715679168701172\n",
      "18 23.609098196029663\n",
      "19 23.648702144622803\n",
      "20 23.58529758453369\n",
      "21 23.299729585647583\n",
      "22 23.162097930908203\n",
      "23 23.126863956451416\n",
      "24 22.977095127105713\n",
      "train error Net_auxiliary_loss 1.00% 10/1000\n",
      "test error Net_auxiliary_loss 22.40% 224/1000\n"
     ]
    }
   ],
   "source": [
    "#WITH BCE\n",
    "####predict class of each digit\n",
    "for k in range(1):\n",
    "    model = Siamese_net_auxiliary()\n",
    "    lr = 0.005\n",
    "    nb_epoch = 25\n",
    "    train_model_CEL(model, train_input, train_classes, train_target, mini_batch_size, lr, nb_epoch)\n",
    "    \n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss 159.10% 1591/1000\n",
      "test error Net_auxiliary_loss 178.20% 1782/1000\n"
     ]
    }
   ],
   "source": [
    "nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                  nb_train_errors_class, train_input.size(0)))\n",
    "nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                nb_test_errors_class, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WITH BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13.854893326759338\n",
      "1 13.82936429977417\n",
      "2 13.821517586708069\n",
      "3 13.816715240478516\n",
      "4 13.813976883888245\n",
      "5 13.812509298324585\n",
      "6 13.811757564544678\n",
      "7 13.811380863189697\n",
      "8 13.811193943023682\n",
      "9 13.811100363731384\n",
      "10 13.811052918434143\n",
      "11 13.811028361320496\n",
      "12 13.811017036437988\n",
      "13 13.811012268066406\n",
      "14 13.811010479927063\n",
      "15 13.811010003089905\n",
      "16 13.81101131439209\n",
      "17 13.811011910438538\n",
      "18 13.811012983322144\n",
      "19 13.81101369857788\n",
      "20 13.811014533042908\n",
      "21 13.811015725135803\n",
      "22 13.811015963554382\n",
      "23 13.81101667881012\n",
      "24 13.811017036437988\n",
      "train error Net_auxiliary_loss 44.90% 449/1000\n",
      "test error Net_auxiliary_loss 47.40% 474/1000\n"
     ]
    }
   ],
   "source": [
    "#WITH BCE\n",
    "####predict class of each digit\n",
    "for k in range(1):\n",
    "    model = Siamese_net_auxiliary()\n",
    "    lr = 0.005\n",
    "    nb_epoch = 25\n",
    "    train_model_BCE(model, train_input, new_train_classes, new_train_target, mini_batch_size, lr, nb_epoch)\n",
    "    \n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR 0.0005\n",
      "train error Net_auxiliary_loss 9.20% 92/1000\n",
      "test error Net_auxiliary_loss 16.90% 169/1000\n",
      "train error Net_auxiliary_loss 171.80% 1718/1000\n",
      "test error Net_auxiliary_loss 178.70% 1787/1000\n",
      "LR 0.001\n",
      "train error Net_auxiliary_loss 7.00% 70/1000\n",
      "test error Net_auxiliary_loss 19.10% 191/1000\n",
      "train error Net_auxiliary_loss 175.70% 1757/1000\n",
      "test error Net_auxiliary_loss 179.10% 1791/1000\n",
      "LR 0.005\n",
      "train error Net_auxiliary_loss 0.90% 9/1000\n",
      "test error Net_auxiliary_loss 18.70% 187/1000\n",
      "train error Net_auxiliary_loss 180.50% 1805/1000\n",
      "test error Net_auxiliary_loss 181.40% 1814/1000\n",
      "LR 0.01\n",
      "train error Net_auxiliary_loss 0.40% 4/1000\n",
      "test error Net_auxiliary_loss 20.10% 201/1000\n",
      "train error Net_auxiliary_loss 180.00% 1800/1000\n",
      "test error Net_auxiliary_loss 182.30% 1823/1000\n",
      "LR 0.05\n",
      "train error Net_auxiliary_loss 44.90% 449/1000\n",
      "test error Net_auxiliary_loss 47.40% 474/1000\n",
      "train error Net_auxiliary_loss 181.80% 1818/1000\n",
      "test error Net_auxiliary_loss 179.00% 1790/1000\n",
      "LR 0.1\n",
      "train error Net_auxiliary_loss 44.90% 449/1000\n",
      "test error Net_auxiliary_loss 47.40% 474/1000\n",
      "train error Net_auxiliary_loss 180.10% 1801/1000\n",
      "test error Net_auxiliary_loss 178.30% 1783/1000\n",
      "LR 0.5\n",
      "train error Net_auxiliary_loss 55.10% 551/1000\n",
      "test error Net_auxiliary_loss 52.60% 526/1000\n",
      "train error Net_auxiliary_loss 180.40% 1804/1000\n",
      "test error Net_auxiliary_loss 180.70% 1807/1000\n"
     ]
    }
   ],
   "source": [
    "#### lr = 0.0005 seems to not overfit\n",
    "for lr in [0.0005, 0.001,0.005, 0.01, 0.05, 0.1, 0.5]:\n",
    "    model = Siamese_net_auxiliary()\n",
    "    nb_epoch = 25\n",
    "    train_model(model, train_input, new_train_classes, new_train_target, mini_batch_size, lr, nb_epoch)\n",
    "    \n",
    "    print(\"LR\", lr)\n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    \n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                      nb_train_errors_class, train_input.size(0)))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                    nb_test_errors_class, test_input.size(0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error Net_auxiliary_loss 16.80% 168/1000\n",
      "test error Net_auxiliary_loss 22.00% 220/1000\n",
      "train error Net_auxiliary_loss 176.80% 1768/1000\n",
      "test error Net_auxiliary_loss 180.00% 1800/1000\n",
      "train error Net_auxiliary_loss 11.70% 117/1000\n",
      "test error Net_auxiliary_loss 19.70% 197/1000\n",
      "train error Net_auxiliary_loss 176.70% 1767/1000\n",
      "test error Net_auxiliary_loss 179.40% 1794/1000\n",
      "train error Net_auxiliary_loss 11.20% 112/1000\n",
      "test error Net_auxiliary_loss 16.40% 164/1000\n",
      "train error Net_auxiliary_loss 177.10% 1771/1000\n",
      "test error Net_auxiliary_loss 180.00% 1800/1000\n",
      "train error Net_auxiliary_loss 14.60% 146/1000\n",
      "test error Net_auxiliary_loss 20.40% 204/1000\n",
      "train error Net_auxiliary_loss 176.50% 1765/1000\n",
      "test error Net_auxiliary_loss 180.50% 1805/1000\n",
      "train error Net_auxiliary_loss 44.90% 449/1000\n",
      "test error Net_auxiliary_loss 47.40% 474/1000\n",
      "train error Net_auxiliary_loss 180.90% 1809/1000\n",
      "test error Net_auxiliary_loss 181.10% 1811/1000\n",
      "train error Net_auxiliary_loss 14.30% 143/1000\n",
      "test error Net_auxiliary_loss 18.40% 184/1000\n",
      "train error Net_auxiliary_loss 179.10% 1791/1000\n",
      "test error Net_auxiliary_loss 180.50% 1805/1000\n",
      "train error Net_auxiliary_loss 20.50% 205/1000\n",
      "test error Net_auxiliary_loss 25.80% 258/1000\n",
      "train error Net_auxiliary_loss 176.00% 1760/1000\n",
      "test error Net_auxiliary_loss 179.20% 1792/1000\n",
      "train error Net_auxiliary_loss 10.00% 100/1000\n",
      "test error Net_auxiliary_loss 17.00% 170/1000\n",
      "train error Net_auxiliary_loss 177.80% 1778/1000\n",
      "test error Net_auxiliary_loss 179.80% 1798/1000\n",
      "train error Net_auxiliary_loss 11.40% 114/1000\n",
      "test error Net_auxiliary_loss 16.90% 169/1000\n",
      "train error Net_auxiliary_loss 175.50% 1755/1000\n",
      "test error Net_auxiliary_loss 181.40% 1814/1000\n",
      "train error Net_auxiliary_loss 14.80% 148/1000\n",
      "test error Net_auxiliary_loss 22.20% 222/1000\n",
      "train error Net_auxiliary_loss 178.80% 1788/1000\n",
      "test error Net_auxiliary_loss 180.00% 1800/1000\n"
     ]
    }
   ],
   "source": [
    "####predict class of each digit\n",
    "for k in range(10):\n",
    "    model = Siamese_net_auxiliary()\n",
    "    lr = 0.0005\n",
    "    nb_epoch = 25\n",
    "    train_model(model, train_input, new_train_classes, new_train_target, mini_batch_size, lr, nb_epoch)\n",
    "    \n",
    "    nb_train_errors = compute_nb_errors_targets(model, train_input, new_train_target)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n",
    "    nb_test_errors = compute_nb_errors_targets(model, test_input, new_test_target)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                    nb_test_errors, test_input.size(0)))\n",
    "    \n",
    "    nb_train_errors_class = compute_nb_errors_classes(model, train_input, new_train_classes)\n",
    "    print('train error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_train_errors_class) / train_input.size(0),\n",
    "                                                      nb_train_errors_class, train_input.size(0)))\n",
    "    nb_test_errors_class = compute_nb_errors_classes(model, test_input, new_test_classes)\n",
    "    print('test error Net_auxiliary_loss {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors_class) / test_input.size(0),\n",
    "                                                    nb_test_errors_class, test_input.size(0)))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
